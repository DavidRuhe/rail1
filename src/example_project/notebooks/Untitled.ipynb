{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "707709ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail1.callbacks.checkpoint import checkpoint, load_checkpoint\n",
    "from rail1.utils.seed import set_seed\n",
    "\n",
    "from torch import nn\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import os\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b57a60a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(steps):\n",
    "    all_inputs = []\n",
    "    all_targets = []\n",
    "    for i in range(steps):\n",
    "        \n",
    "        inputs = torch.randn(32, 10).cuda()  # Batch size of 32\n",
    "        targets = torch.randn(32, 1).cuda()  # Corresponding targets\n",
    "        \n",
    "        all_inputs.append(inputs)\n",
    "        all_targets.append(targets)\n",
    "        \n",
    "    return torch.stack(all_inputs), torch.stack(all_targets)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2921ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0, deterministic=True)\n",
    "data_1 = generate_data(32)\n",
    "\n",
    "random_state_dict = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "torch.set_rng_state(random_state_dict[\"torch\"])\n",
    "torch.cuda.set_rng_state(random_state_dict[\"cuda\"])\n",
    "torch.cuda.set_rng_state_all(random_state_dict[\"cuda_all\"])\n",
    "numpy.random.set_state(random_state_dict[\"numpy\"])\n",
    "random.setstate(random_state_dict[\"random\"])\n",
    "\n",
    "\n",
    "data_2 = generate_data(32)\n",
    "\n",
    "set_seed(0, deterministic=True)\n",
    "\n",
    "\n",
    "data_1_ = generate_data(32)\n",
    "data_2_ = generate_data(32)\n",
    "\n",
    "\n",
    "assert torch.allclose(data_1[0], data_1_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f35efe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7592a1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple feed-forward neural network\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)  # Assuming input features are of size 10\n",
    "        self.fc2 = nn.Linear(50, 1)   # Output layer (e.g., for regression or binary classification)\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        for m in self.children():\n",
    "            if hasattr(m, 'reset_parameters'):\n",
    "                m.reset_parameters()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5b5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, steps):\n",
    "    model.train()\n",
    "    for _ in range(steps):\n",
    "        inputs = torch.randn(32, 10).cuda()  # Batch size of 32\n",
    "        targets = torch.randn(32, 1).cuda()  # Corresponding targets\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = torch.nn.functional.mse_loss(outputs, targets)  # Mean Squared Error Loss for simplicity\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95d9dc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_models_equal(model1, model2):\n",
    "    for p in model1.state_dict():\n",
    "        v1 = model1.state_dict()[p]\n",
    "        v2 = model2.state_dict()[p]\n",
    "\n",
    "        print(torch.equal(v1, v2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "887f8ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "set_seed(0, deterministic=True)\n",
    "\n",
    "# Initialize models and optimizer\n",
    "model1 = SimpleModel().cuda()\n",
    "optimizer1 = optim.Adam(model1.parameters())\n",
    "\n",
    "# Train model1 for a few steps and checkpoint\n",
    "train_model(model1, optimizer1, steps=64)\n",
    "\n",
    "\n",
    "set_seed(0, deterministic=True)\n",
    "model2 = SimpleModel().cuda()\n",
    "optimizer2 = optim.Adam(model2.parameters())\n",
    "\n",
    "\n",
    "# Train model1 for a few steps and checkpoint\n",
    "train_model(model2, optimizer2, steps=32)\n",
    "random_state_dict = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "model2_state_dict = model2.state_dict()\n",
    "optimizer2_state_dict = optimizer2.state_dict()\n",
    "\n",
    "checkpoint = {\n",
    "    \"model\": model2_state_dict,\n",
    "    \"optimizer\": optimizer2_state_dict,\n",
    "    \"random_state\": random_state_dict,\n",
    "}\n",
    "torch.save(checkpoint, './checkpoint.pt')\n",
    "del checkpoint\n",
    "\n",
    "\n",
    "set_seed(0)\n",
    "model2.reset_parameters()\n",
    "\n",
    "checkpoint = torch.load('./checkpoint.pt')\n",
    "model2_state_dict = checkpoint['model']\n",
    "model2.load_state_dict(model2_state_dict)\n",
    "optimizer2_state_dict = checkpoint['optimizer']\n",
    "optimizer2.load_state_dict(optimizer2_state_dict)\n",
    "random_state_dict = checkpoint['random_state']\n",
    "\n",
    "torch.set_rng_state(random_state_dict[\"torch\"])\n",
    "torch.cuda.set_rng_state(random_state_dict[\"cuda\"])\n",
    "torch.cuda.set_rng_state_all(random_state_dict[\"cuda_all\"])\n",
    "numpy.random.set_state(random_state_dict[\"numpy\"])\n",
    "random.setstate(random_state_dict[\"random\"])\n",
    "\n",
    "train_model(model2, optimizer2, steps=32)\n",
    "\n",
    "_print_models_equal(model1, model2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_model(model1, optimizer1, steps=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0964c34a",
   "metadata": {},
   "source": [
    "# Deterministic train loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6de4ad6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "944f1cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fed73058",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InfiniteRandomSampler(Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            index = random.randint(0, len(self.data_source) - 1)\n",
    "            yield index\n",
    "\n",
    "    def __len__(self):\n",
    "        return torch.iinfo(torch.int64).max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a5925f77",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 16\u001b[0m\n\u001b[1;32m      4\u001b[0m mnist \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m~/.pytorch/MNIST_data/\u001b[39m\u001b[38;5;124m'\u001b[39m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# dataset = torch.arange(128)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# trainloader1 = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=InfiniteRandomSampler(dataset))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#         break\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# dataset = torch.arange(128)\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m sampler \u001b[38;5;241m=\u001b[39m InfiniteRandomSampler(\u001b[43mdataset\u001b[49m)\n\u001b[1;32m     17\u001b[0m sampler_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(sampler)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# trainloader1 = torch.utils.data.DataLoader(mnist, batch_size=32, sampler=InfiniteRandomSampler(dataset))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "set_seed(0, deterministic=True)\n",
    "\n",
    "# # Download and load the training data\n",
    "mnist = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transforms.ToTensor())\n",
    "# dataset = torch.arange(128)\n",
    "# trainloader1 = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "\n",
    "# for i, batch in enumerate(trainloader1):\n",
    "#     images = batch\n",
    "#     print(images.sum())\n",
    "    \n",
    "#     if i == 16:\n",
    "#         break\n",
    "# dataset = torch.arange(128)\n",
    "sampler = InfiniteRandomSampler(dataset)\n",
    "sampler_iter = iter(sampler)\n",
    "\n",
    "# trainloader1 = torch.utils.data.DataLoader(mnist, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "random_state_dict_a = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "for i, batch in enumerate(dataset):\n",
    "    batch = [next(sampler_iter) for i in range(8)]\n",
    "    batch = [mnist[i] for i in batch]\n",
    "    images, labels = zip(*batch)\n",
    "    print(torch.stack(images).sum())\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "random_state_dict_b = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "torch.set_rng_state(random_state_dict_b[\"torch\"])\n",
    "torch.cuda.set_rng_state(random_state_dict_b[\"cuda\"])\n",
    "torch.cuda.set_rng_state_all(random_state_dict_b[\"cuda_all\"])\n",
    "numpy.random.set_state(random_state_dict_b[\"numpy\"])\n",
    "random.setstate(random_state_dict_b[\"random\"])\n",
    "\n",
    "\n",
    "\n",
    "dataset = torch.arange(128)\n",
    "sampler = InfiniteRandomSampler(dataset)\n",
    "# trainloader2 = torch.utils.data.DataLoader(mnist, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "sampler_iter = iter(sampler)\n",
    "\n",
    "print(torch.allclose(random_state_dict_b['torch'], torch.get_rng_state()))\n",
    "\n",
    "for i, batch in enumerate(dataset):\n",
    "    batch = [next(sampler_iter) for i in range(8)]\n",
    "    batch = [mnist[i] for i in batch]\n",
    "    images, labels = zip(*batch)\n",
    "    print(torch.stack(images).sum())\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "\n",
    "random_state_dict_c = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "\n",
    "print(torch.allclose(random_state_dict_b['torch'],random_state_dict_c['torch']))\n",
    "\n",
    "# dataset = torch.arange(128)\n",
    "# trainloader2 = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "# print()\n",
    "# for i, batch in enumerate(trainloader2):\n",
    "#     images = batch\n",
    "#     print(images.sum())\n",
    "    \n",
    "#     if i == 16:\n",
    "#         break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6776898",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_a['torch']))\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_b['torch']))\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_c['torch']))\n",
    "\n",
    "\n",
    "dataset = torch.arange(128)\n",
    "sampler = InfiniteRandomSampler(dataset)\n",
    "sampler_iter = iter(sampler)\n",
    "# trainloader3 = torch.utils.data.DataLoader(mnist, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "for i, batch in enumerate(dataset):\n",
    "\n",
    "    batch = [next(sampler_iter) for i in range(8)]\n",
    "    batch = [mnist[i] for i in batch]\n",
    "    images, labels = zip(*batch)\n",
    "    print(torch.stack(images).sum())\n",
    "    if i == 5:\n",
    "        break\n",
    "\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_c['torch']))\n",
    "print(torch.allclose(random_state_dict_b['torch'], random_state_dict_c['torch']))\n",
    "\n",
    "\n",
    "# dataset = torch.arange(128)\n",
    "# trainloader3 = torch.utils.data.DataLoader(dataset, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "\n",
    "# print()\n",
    "# for i, batch in enumerate(trainloader3):\n",
    "#     images = batch\n",
    "    \n",
    "#     print(images.sum())\n",
    "    \n",
    "#     if i == 32:\n",
    "#         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ede44",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_a['torch']))\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_b['torch']))\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_c['torch']))\n",
    "\n",
    "\n",
    "dataset = torch.arange(128)\n",
    "sampler = InfiniteRandomSampler(dataset)\n",
    "trainloader3 = torch.utils.data.DataLoader(mnist, batch_size=32, sampler=InfiniteRandomSampler(dataset))\n",
    "for i, batch in enumerate(trainloader3):\n",
    "\n",
    "    print(batch[0].sum())\n",
    "    if i == 4:\n",
    "        break\n",
    "\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_b['torch']))\n",
    "\n",
    "print(torch.allclose(torch.get_rng_state(), random_state_dict_c['torch']))\n",
    "print(torch.allclose(random_state_dict_b['torch'], random_state_dict_c['torch']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63326c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Sampler\n",
    "import math\n",
    "\n",
    "\n",
    "class InfiniteRandomSampler(Sampler):\n",
    "    def __init__(self, data_source):\n",
    "        self.data_source = data_source\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            index = random.randint(0, len(self.data_source) - 1)  # type: ignore\n",
    "            yield index\n",
    "\n",
    "    def __len__(self):\n",
    "        return torch.iinfo(torch.int64).max\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f18859",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "dataset = torch.arange(128)\n",
    "sampler = InfiniteRandomSampler(dataset)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, sampler=sampler)\n",
    "\n",
    "class CustomDataLoader:\n",
    "    def __init__(self, dataset, sampler, batch_size=1):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.sampler = sampler\n",
    "        \n",
    "    def __iter__(self):\n",
    "        batch_indices = []\n",
    "        for index in self.sampler:\n",
    "            batch_indices.append(index)\n",
    "            if len(batch_indices) == self.batch_size:\n",
    "                yield [self.dataset[i] for i in batch_indices]\n",
    "                batch_indices = []\n",
    "\n",
    "        if batch_indices:\n",
    "            yield [self.dataset[i] for i in batch_indices]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sampler)\n",
    "    \n",
    "\n",
    "dataloader = CustomDataLoader(dataset, sampler=sampler, batch_size=3)\n",
    "\n",
    "\n",
    "random_state_0 = torch.get_rng_state()\n",
    "\n",
    "# for i, batch in enumerate(range(len(dataloader))):  # WORKS\n",
    "for i, batch in enumerate(dataloader):  # DOES NOT WORK\n",
    "# for i, batch in enumerate(dataset):  # DOES NOT WORK\n",
    "\n",
    "# for i, batch in enumerate(range(10)):  # WORKS\n",
    "\n",
    "    x = torch.randn(32)\n",
    "    if i == 2:\n",
    "        break\n",
    "    \n",
    "random_state_2 = torch.get_rng_state()\n",
    "    \n",
    "\n",
    "\n",
    "for i, batch in enumerate(range(len(dataloader))):  # WORKS\n",
    "# for i, batch in enumerate(dataloader):  # DOES NOT WORK\n",
    "# for i, batch in enumerate(range(10)):  # WORKS\n",
    "\n",
    "    x = torch.randn(32)\n",
    "    if i == 2:\n",
    "        break\n",
    "random_state_4 = torch.get_rng_state()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57c7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(0)\n",
    "dataset = torch.arange(128)\n",
    "sampler = iter(InfiniteRandomSampler(dataset))\n",
    "\n",
    "\n",
    "# for i, batch in enumerate(range(len(dataloader))): # WORKS\n",
    "# for i, batch in enumerate(dataset):  # DOES NOT WORK\n",
    "for i, batch in enumerate(dataloader):  # DOES NOT WORK\n",
    "# for i, batch in enumerate(range(10)):  # WORKS\n",
    "\n",
    "    x = torch.randn(32)\n",
    "    \n",
    "    if i == 2:\n",
    "        print(torch.allclose(torch.get_rng_state(), random_state_2))\n",
    "        \n",
    "    if i == 5:\n",
    "        print(torch.allclose(torch.get_rng_state(), random_state_4))\n",
    "        break\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e176024",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99b4eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rail1 import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3987cdde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor(716.1142)\n",
      "tensor(711.8868)\n",
      "tensor(730.3835)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor(734.9149)\n",
      "tensor(731.8375)\n",
      "tensor(735.6448)\n"
     ]
    }
   ],
   "source": [
    "set_seed(0, deterministic=True)\n",
    "\n",
    "train_loader = datasets.cifar10()['train_loader']\n",
    "for i, batch in enumerate(train_loader):\n",
    "    images, labels = batch\n",
    "    print(images.sum())\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "random_state_dict = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n",
    "set_seed(0)\n",
    "\n",
    "torch.set_rng_state(random_state_dict[\"torch\"])\n",
    "torch.cuda.set_rng_state(random_state_dict[\"cuda\"])\n",
    "torch.cuda.set_rng_state_all(random_state_dict[\"cuda_all\"])\n",
    "numpy.random.set_state(random_state_dict[\"numpy\"])\n",
    "random.setstate(random_state_dict[\"random\"])\n",
    "\n",
    "\n",
    "\n",
    "train_loader = datasets.cifar10()['train_loader']\n",
    "for i, batch in enumerate(train_loader):\n",
    "    images, labels = batch\n",
    "    print(images.sum())\n",
    "    if i == 2:\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "random_state_dict = {\n",
    "    \"torch\": torch.get_rng_state(),\n",
    "    \"numpy\": numpy.random.get_state(),\n",
    "    \"random\": random.getstate(),\n",
    "    \"cuda\": torch.cuda.get_rng_state(),\n",
    "    \"cuda_all\": torch.cuda.get_rng_state_all(),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48e6f96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "tensor(716.1142)\n",
      "tensor(711.8868)\n",
      "tensor(730.3835)\n",
      "tensor(734.9149)\n",
      "tensor(731.8375)\n",
      "tensor(735.6448)\n"
     ]
    }
   ],
   "source": [
    "set_seed(0)\n",
    "\n",
    "\n",
    "\n",
    "train_loader = datasets.cifar10()['train_loader']\n",
    "for i, batch in enumerate(train_loader):\n",
    "    images, labels = batch\n",
    "    print(images.sum())\n",
    "    if i == 5:\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9d8db0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
