{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import ip_cuda\n",
    "\n",
    "\n",
    "class DotFunction(torch.autograd.Function):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input_left, metric, input_right):\n",
    "        outputs = ip_cuda.forward(input_left, metric, input_right)\n",
    "        new_h = outputs[0]\n",
    "        # variables = outputs[1:] + [weights]\n",
    "        variables = [input_left, metric, input_right]\n",
    "        ctx.save_for_backward(*variables)\n",
    "        return new_h\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_h):\n",
    "        grad_input_left, grad_input_right = ip_cuda.backward(\n",
    "            grad_h[None].contiguous(), *ctx.saved_tensors\n",
    "        )\n",
    "        return grad_input_left, None, grad_input_right\n",
    "\n",
    "\n",
    "class Dot(torch.nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.input_left = nn.Parameter(torch.arange(size).float() + 10)\n",
    "        self.input_right = nn.Parameter(torch.arange(size).float())\n",
    "\n",
    "    def forward(self, metric):\n",
    "        # return DotFunction.apply(self.input_left, metric, self.input_right)\n",
    "        return torch.einsum('i, ij, j ->', self.input_left, metric, self.input_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = torch.randn(1024, 1024).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396 µs ± 6.13 µs per loop (mean ± std. dev. of 128 runs, 128 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 128 -r 128\n",
    "module = Dot(1024).cuda()\n",
    "module(metric).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,   1.0463,  -0.8177,  ..., -86.8748, 194.3297, 217.4943],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = Dot(1024).cuda()\n",
    "module(metric).sum().backward()\n",
    "module.input_left.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "269 µs ± 5.28 µs per loop (mean ± std. dev. of 128 runs, 128 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 128 -r 128\n",
    "module = Dot(1024).cuda()\n",
    "module(metric).sum().backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.0000,   1.0463,  -0.8177,  ..., -86.8748, 194.3297, 217.4943],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module = Dot(1024).cuda()\n",
    "module(metric).sum().backward()\n",
    "module.input_left.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykeops.torch import LazyTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(10, 100000, 1, 500)\n",
    "B = torch.randn(10000, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100000, 1, 1, 500) (1, 1, 10000, 500)\n"
     ]
    }
   ],
   "source": [
    "A_i = LazyTensor(A[:, :, None, :])\n",
    "B_j = LazyTensor(B[None, None, :, :])\n",
    "\n",
    "print(A_i.shape, B_j.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible batch dimensions: (64,) and (1024,).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m B_lazy \u001b[38;5;241m=\u001b[39m LazyTensor(B[:, :, \u001b[38;5;28;01mNone\u001b[39;00m, :])  \u001b[38;5;66;03m# Reshape B to [1024, 32, 1, 8] for broadcasting\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Perform matrix multiplication\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# The operation implicitly sums over the last dimension of A and B, which is the dot product\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m (\u001b[43mA_lazy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB_lazy\u001b[49m)\u001b[38;5;241m.\u001b[39msum(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Summing over the last dimension (dim=3)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# The result here is a LazyTensor. To get a NumPy array or PyTorch tensor, use .numpy() or .tensor() respectively\u001b[39;00m\n\u001b[1;32m     16\u001b[0m result_np \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mnumpy()  \u001b[38;5;66;03m# Assuming you want a numpy array\u001b[39;00m\n",
      "File \u001b[0;32m~/rail1/src/cuda/.venv/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:1111\u001b[0m, in \u001b[0;36mGenericLazyTensor.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlt_constructor(other)\u001b[38;5;241m.\u001b[39mmulop(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rail1/src/cuda/.venv/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:1091\u001b[0m, in \u001b[0;36mGenericLazyTensor.mulop\u001b[0;34m(self, other, **kwargs)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmulop\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_operator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rail1/src/cuda/.venv/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:537\u001b[0m, in \u001b[0;36mGenericLazyTensor.binary\u001b[0;34m(self, other, operation, is_operator, dimres, dimcheck, opt_arg, opt_pos, rversion, is_complex)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m dimcheck \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect dimcheck keyword in binary operation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 537\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_complex\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Merge the attributes and variables of both operands\u001b[39;00m\n\u001b[1;32m    541\u001b[0m res\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m=\u001b[39m dimres\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rversion:\n",
      "File \u001b[0;32m~/rail1/src/cuda/.venv/lib/python3.10/site-packages/pykeops/common/lazy_tensor.py:424\u001b[0m, in \u001b[0;36mGenericLazyTensor.join\u001b[0;34m(self, other, is_complex)\u001b[0m\n\u001b[1;32m    421\u001b[0m res\u001b[38;5;241m.\u001b[39msymbolic_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msymbolic_variables \u001b[38;5;241m+\u001b[39m other\u001b[38;5;241m.\u001b[39msymbolic_variables\n\u001b[1;32m    423\u001b[0m \u001b[38;5;66;03m# Checks on the batch dimensions - we support broadcasting:\u001b[39;00m\n\u001b[0;32m--> 424\u001b[0m res\u001b[38;5;241m.\u001b[39mbatchdims \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_broadcasting\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatchdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;66;03m# N.B.: If needed, variables will be padded with \"dummy 1's\" just before the Genred call, in self/res.fixvariables():\u001b[39;00m\n\u001b[1;32m    426\u001b[0m res\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables \u001b[38;5;241m+\u001b[39m other\u001b[38;5;241m.\u001b[39mvariables\n",
      "File \u001b[0;32m~/rail1/src/cuda/.venv/lib/python3.10/site-packages/pykeops/common/utils.py:91\u001b[0m, in \u001b[0;36mcheck_broadcasting\u001b[0;34m(dims_1, dims_2)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dim_1, dim_2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(padded_dims_1, padded_dims_2):\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dim_1 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim_2 \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim_1 \u001b[38;5;241m!=\u001b[39m dim_2:\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible batch dimensions: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(dims_1, dims_2)\n\u001b[1;32m     93\u001b[0m         )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m max_tuple(padded_dims_1, padded_dims_2)\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible batch dimensions: (64,) and (1024,)."
     ]
    }
   ],
   "source": [
    "from pykeops.numpy import LazyTensor\n",
    "import numpy as np\n",
    "\n",
    "A = np.random.randn(64, 8)\n",
    "B = np.random.randn(1024, 32, 8)\n",
    "\n",
    "# Assuming A and B are your numpy arrays or torch tensors with the specified shapes\n",
    "A_lazy = LazyTensor(A[:, None, :, None])  # Reshape A to [64, 1, 8, 1] for broadcasting\n",
    "B_lazy = LazyTensor(B[:, :, None, :])  # Reshape B to [1024, 32, 1, 8] for broadcasting\n",
    "\n",
    "# Perform matrix multiplication\n",
    "# The operation implicitly sums over the last dimension of A and B, which is the dot product\n",
    "result = (A_lazy * B_lazy).sum(dim=-1)  # Summing over the last dimension (dim=3)\n",
    "\n",
    "# The result here is a LazyTensor. To get a NumPy array or PyTorch tensor, use .numpy() or .tensor() respectively\n",
    "result_np = result.numpy()  # Assuming you want a numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m b \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Compute the inner product\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.randn(32, 1024, 8)\n",
    "b = torch.randn(1, 64, 8)\n",
    "# Compute the inner product\n",
    "result = torch.matmul(a, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1024, 1, 8])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[..., None, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32, 8, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[..., None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1024, 8)\n",
    "b = torch.randn(64, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 8, 1])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:, :, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6063, -0.4657, -0.3143,  ..., -2.0547, -1.8664,  0.1886],\n",
       "        [-2.0564, -1.6379, -0.2408,  ..., -2.5238, -1.0698,  1.7206],\n",
       "        [ 4.3503,  3.2547,  1.9063,  ...,  6.3056,  0.8429, -1.9911],\n",
       "        ...,\n",
       "        [-7.5581, -7.3256,  2.4146,  ..., -0.4229,  6.6804,  0.5273],\n",
       "        [ 2.8416, -1.0463,  0.2835,  ..., -2.8278,  1.5270,  6.4478],\n",
       "        [ 4.2925,  0.2785,  1.7750,  ...,  2.6925,  3.6638,  7.7907]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a @ b.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = torch.randn(8, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.3855e-01,  1.5969e+00, -2.4437e+00,  ..., -6.4465e-02,\n",
       "          -8.2941e-01, -4.0274e+00],\n",
       "         [-3.8261e+00, -3.8148e+00, -8.3644e-01,  ...,  1.2726e+00,\n",
       "           6.9474e+00, -3.7049e+00],\n",
       "         [-1.0028e+01, -9.0609e+00,  2.7482e+00,  ..., -7.5631e+00,\n",
       "           4.4813e+00,  9.3730e-01],\n",
       "         ...,\n",
       "         [-3.8833e+00, -4.0569e+00,  5.0064e+00,  ..., -3.1980e+00,\n",
       "           1.4440e+00,  5.3010e+00],\n",
       "         [-3.5084e+00, -9.3427e-01,  3.5669e+00,  ..., -3.1311e+00,\n",
       "          -2.9810e+00,  7.4572e-01],\n",
       "         [-3.4574e+00,  2.6998e+00,  5.5797e+00,  ...,  6.4986e-01,\n",
       "           2.7864e+00,  9.6783e-01]],\n",
       "\n",
       "        [[-2.0395e+00,  2.2895e+00, -1.5884e+01,  ..., -2.9234e+00,\n",
       "          -1.8282e+01, -1.7510e+01],\n",
       "         [-2.0357e+01, -1.2736e+01, -2.2818e+00,  ..., -9.4535e+00,\n",
       "           2.3496e+00, -1.7532e+01],\n",
       "         [-5.8222e+00, -5.7164e+00,  1.7074e+00,  ..., -5.8486e+00,\n",
       "           8.9439e-01, -2.8988e+00],\n",
       "         ...,\n",
       "         [-4.2642e+00, -6.0505e+00,  3.5785e+00,  ..., -9.6592e+00,\n",
       "           3.8507e+00,  1.0302e+01],\n",
       "         [ 1.7073e+01,  1.1944e+01,  3.5172e+00,  ...,  2.8294e-01,\n",
       "          -7.5269e+00,  1.0011e+01],\n",
       "         [ 1.8038e+01,  9.0443e+00, -5.5610e+00,  ...,  7.6836e+00,\n",
       "          -1.1229e+01,  6.8749e+00]],\n",
       "\n",
       "        [[ 3.3225e+00, -2.7123e-01,  6.3465e+00,  ...,  5.8646e+00,\n",
       "           6.0278e+00,  1.4233e+01],\n",
       "         [ 2.1389e+01,  1.3618e+01, -6.2490e+00,  ...,  1.6280e+00,\n",
       "          -1.5163e+01,  1.0305e+01],\n",
       "         [ 2.5540e+01,  1.9051e+01, -1.0170e+00,  ...,  1.7451e+01,\n",
       "          -1.0725e+01,  5.4901e+00],\n",
       "         ...,\n",
       "         [ 9.1343e+00,  2.7493e+00, -1.0087e+00,  ...,  2.3038e+00,\n",
       "           1.0051e+01,  1.8830e+00],\n",
       "         [-9.8741e+00, -1.6982e+01, -1.6032e+01,  ..., -1.9512e+00,\n",
       "           9.1939e+00, -1.0526e+01],\n",
       "         [ 1.8431e+00, -1.2378e-01, -8.4862e+00,  ...,  3.6818e-02,\n",
       "          -1.2592e+01, -9.5842e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.7379e+01, -8.8514e+00, -1.3298e+01,  ...,  7.4895e-01,\n",
       "           7.1667e+00, -2.8656e+01],\n",
       "         [ 1.0187e+01,  7.6597e-01, -1.4334e+01,  ..., -9.9517e-01,\n",
       "          -4.9417e+00, -9.3238e+00],\n",
       "         [ 1.5259e+01,  6.5872e+00,  1.6721e+01,  ...,  8.1704e+00,\n",
       "           1.2761e+01,  5.7041e+00],\n",
       "         ...,\n",
       "         [-5.0688e+00, -8.8988e+00, -1.5414e+01,  ..., -4.1075e+00,\n",
       "           4.0087e+00, -1.6259e+01],\n",
       "         [-1.0878e+01, -1.0155e+01,  1.5810e+01,  ..., -5.7491e+00,\n",
       "           1.9695e+01,  1.5330e+01],\n",
       "         [ 2.5912e+01,  1.3121e+01, -4.7945e+00,  ...,  2.3337e+01,\n",
       "          -5.6590e-01,  1.9865e+00]],\n",
       "\n",
       "        [[-1.0124e+01, -7.1095e+00,  5.1571e+00,  ..., -1.6964e+01,\n",
       "          -3.3264e+00, -6.7220e-01],\n",
       "         [-2.1598e+01, -8.2046e+00,  2.4188e+00,  ..., -1.1694e+01,\n",
       "          -1.4484e+00, -1.7209e+01],\n",
       "         [-2.1130e+01, -8.1103e+00, -7.0592e+00,  ..., -7.4725e+00,\n",
       "          -1.6978e+00, -1.8401e+01],\n",
       "         ...,\n",
       "         [ 2.8136e+00,  8.7803e+00,  5.8517e-01,  ...,  6.2894e+00,\n",
       "          -1.1269e+01, -5.0520e+00],\n",
       "         [ 2.1288e+01,  2.2374e+01, -8.5107e-01,  ...,  5.9129e+00,\n",
       "          -1.1531e+01, -4.1763e+00],\n",
       "         [ 6.9618e+00, -2.0806e-02, -6.7639e-02,  ..., -3.2723e+00,\n",
       "           4.2923e+00,  1.1193e+01]],\n",
       "\n",
       "        [[-2.2111e+01, -9.4174e+00, -2.0900e+00,  ..., -1.4827e+01,\n",
       "          -1.6948e+00,  1.1331e+00],\n",
       "         [-1.9176e+01, -5.1081e+00, -1.8418e+01,  ..., -1.6513e+01,\n",
       "          -8.7615e+00, -3.1063e+01],\n",
       "         [-1.4700e+01, -1.0278e+01,  3.5354e+00,  ..., -1.3028e+01,\n",
       "           1.5257e+00,  4.0208e-01],\n",
       "         ...,\n",
       "         [-4.4302e+00, -1.4117e+00, -4.6319e+00,  ...,  7.2903e-01,\n",
       "          -4.2391e+00, -9.5482e+00],\n",
       "         [ 1.1491e+01,  6.5393e+00, -8.1909e+00,  ...,  6.9201e+00,\n",
       "           1.9404e-01, -8.8651e+00],\n",
       "         [ 2.6371e+00,  2.1805e+00, -9.9955e+00,  ..., -3.8971e+00,\n",
       "          -3.4561e+00, -6.6309e+00]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((a @ M.view(8, 64)).view(1024 * 8, 8) @ b.T).view(1024, 8, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.randn(1024, 8)\n",
    "B = torch.randn(1024, 8)\n",
    "M = torch.randn(8, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = torch.einsum('bi, ijk, bk -> bj', A, M, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 8])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8192, 1024])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = ((A @ M.view(8, 64)).view(1024 * 8, 8) @ B.T)\n",
    "\n",
    "result2.shape\n",
    "# .view(1024, 8, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left = (A @ M.view(8, 64)).view(1024, 8, 8) \n",
    "torch.allclose(left, torch.einsum('bi, ijk -> bjk', A, M))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'A' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m left \u001b[38;5;241m=\u001b[39m (\u001b[43mA\u001b[49m \u001b[38;5;241m@\u001b[39m M\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m64\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'A' is not defined"
     ]
    }
   ],
   "source": [
    "left = (A @ M.view(8, 64)).view(1024 * 8, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1024, 8, 512]' is invalid for input of size 8388608",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m8\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m M \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[0;32m----> 5\u001b[0m result1 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m result1\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      7\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1024, 8, 512]' is invalid for input of size 8388608"
     ]
    }
   ],
   "source": [
    "# %%timeit -n 256 -r 256\n",
    "A = torch.randn(32, 32, 8, device='cuda', requires_grad=True)\n",
    "B = torch.randn(32, 32, 8, device='cuda', requires_grad=True)\n",
    "M = torch.randint(0, 2, (8, 8, 8), device='cuda').float()\n",
    "result1 = ((A.view(-1, 8) @ M.view(8, 64)).view(1024 * 8, 8) @ B.view(-1, 8).T).view(1024, 8, 512).transpose(1, 2)\n",
    "loss = result1.sum()\n",
    "loss.backward()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def geometric_product(left, cayley, right):\n",
    "    assert left.shape == right.shape\n",
    "    shape = left.shape\n",
    "    left = left.view(-1, shape[-1])\n",
    "    right = right.view(-1, shape[-1])\n",
    "    result = left.matmul(cayley.view(cayley.shape[0], -1)).view(-1, cayley.shape[1], cayley.shape[2]).matmul(right[..., None]).squeeze(-1)\n",
    "    return result.view(*shape[:-1], shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.03 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "6.92 ms ± 3.22 ms per loop (mean ± std. dev. of 64 runs, 64 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 64 -r 64\n",
    "A = torch.randn(32, 32, 32, 32, 8, device='cuda', requires_grad=True)\n",
    "B = torch.randn(32, 32, 32, 32, 8, device='cuda', requires_grad=True)\n",
    "M = torch.randint(0, 2, (8, 8, 8), device='cuda').float()\n",
    "result1 = geometric_product(A, M, B)\n",
    "loss = result1.sum()\n",
    "loss.backward()\n",
    "torch.cuda.synchronize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.55 ms ± 22.8 µs per loop (mean ± std. dev. of 64 runs, 64 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 64 -r 64\n",
    "A = torch.randn(32, 32, 32, 32, 8, device='cuda', requires_grad=True)\n",
    "B = torch.randn(32, 32, 32, 32, 8, device='cuda', requires_grad=True)\n",
    "M = torch.randint(0, 2, (8, 8, 8), device='cuda').float()\n",
    "result2 = torch.einsum('b...i, ijk, b...k -> b...j', A, M, B)\n",
    "loss = result2.sum()\n",
    "loss.backward()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "591 µs ± 6.81 µs per loop (mean ± std. dev. of 256 runs, 256 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 256 -r 256\n",
    "A = torch.randn(32, 32, 8, device='cuda', requires_grad=True)\n",
    "B = torch.randn(16, 32, 8, device='cuda', requires_grad=True)\n",
    "M = torch.randint(0, 2, (8, 8, 8), device='cuda').float()\n",
    "result2 = torch.einsum('b...i, ijk, cak -> b...caj', A, M, B).view(result1.shape)\n",
    "loss = result2.sum()\n",
    "loss.backward()\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1024, 512, 8]), torch.Size([1024, 512, 8]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1.shape, result2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 - result2.view(result1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
